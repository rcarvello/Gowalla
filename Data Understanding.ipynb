{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <b> <h1> Gowalla, Stalker pattern recognition </h1></b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 id=\"challenge\">Challenge</h4>\n",
    "\n",
    "<p>Use the dataset here: <a href=\"https://snap.stanford.edu/data/loc-gowalla.html\">https://snap.stanford.edu/data/loc-gowalla.html</a></p>\n",
    "\n",
    "<ul>\n",
    "  <li>Assume a “stalker” is someone who, in this dataset, visits some of the same locations as another person, after the other person goes to that location.</li>\n",
    "  <li>A “stalker score” for a pair of people, A &amp; B, is the number of locations for which A has visited a location followed by B visiting that same location in the future.</li>\n",
    "  <li>Any given location should be counted once in the score, so a stalker score can never be higher than the number of unique locations that A and B have in common.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Use the datasets from the web page above to answer the following questions:</p>\n",
    "\n",
    "<ol>\n",
    "  <li>Which friend pair has the highest “stalker score”?</li>\n",
    "  <li>Which non-friend pair has the highest “stalker score”?</li>\n",
    "</ol>\n",
    "\n",
    "<p>You can use any tools you want to solve this puzzle, except asking for help from other people. Please feel free to email at any time for any clarifications.</p>\n",
    "\n",
    "<p>Please give the winning user id pairs and “stalker score” for each question, and please explain your solution methods, including any source code if you wrote any.</p>\n",
    "\n",
    "<p>There are many libraries available that can make this challenge easier, so we are offering bonus points for:</p>\n",
    "<ul>\n",
    "  <li>Using as little RAM as possible</li>\n",
    "  <li>Exection speed</li>\n",
    "  <li>Pure python solution using base modules</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <b> <h3> <em>Script and Macine characteristics</em> </h3></b>\n",
    "\n",
    "<p style=\"text-align:justify\">\n",
    "    This project will be implemented with PIP-8 style guide of python, I will evaluate computation time, size in memory, if it is possible, I will implement concurrency.The computer in which this scrip will be developed has a CPU intel core i5 of third generation with four threads and 2.5 Gz, 8GB of RAM, standard hard-disk of 512GB,  executing Ubuntu 16.04.\n",
    "\n",
    "This script is powered by python 3.7 (anaconda distribution). \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "PATH_CHECKINGS = \"datasets/Gowalla_totalCheckins.txt\"\n",
    "PATH_EDGES = \"datasets/Gowalla_edges.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edges = pd.read_csv(PATH_EDGES, sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  0  1\n",
       "1  0  2\n",
       "2  0  3\n",
       "3  0  4\n",
       "4  0  5"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_checkins = pd.read_csv(PATH_CHECKINGS, sep=\"\\t\", header=None)\n",
    "data_checkins.columns = [\"user\", \"check-in time\", \"latitude\", \"longitude\", \"location id\"]\n",
    "data_checkins.set_index(\"location id\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>check-in time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22847</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-19T23:55:27Z</td>\n",
       "      <td>30.235909</td>\n",
       "      <td>-97.795140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420315</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-18T22:17:43Z</td>\n",
       "      <td>30.269103</td>\n",
       "      <td>-97.749395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316637</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-17T23:42:03Z</td>\n",
       "      <td>30.255731</td>\n",
       "      <td>-97.763386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16516</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-17T19:26:05Z</td>\n",
       "      <td>30.263418</td>\n",
       "      <td>-97.757597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535878</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-16T18:50:42Z</td>\n",
       "      <td>30.274292</td>\n",
       "      <td>-97.740523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user         check-in time   latitude  longitude\n",
       "location id                                                  \n",
       "22847           0  2010-10-19T23:55:27Z  30.235909 -97.795140\n",
       "420315          0  2010-10-18T22:17:43Z  30.269103 -97.749395\n",
       "316637          0  2010-10-17T23:42:03Z  30.255731 -97.763386\n",
       "16516           0  2010-10-17T19:26:05Z  30.263418 -97.757597\n",
       "5535878         0  2010-10-16T18:50:42Z  30.274292 -97.740523"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_checkins.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan to addres this problem wil be:\n",
    "\n",
    "-  <b> <em> Preprocess the raw-data: </em></b></i> <p style=\"text-align:justify\">let's deletete the information that there is not important for our challenge, (<b><em>latitude, longitude</em></b>). in each step it will shown how change the size of the data. I will create a Sparse matrix Object to represent the matrices. we will have 3 matrix: friend_relationship, stalker_score, locations_chekins. for better explanation, in each step there will be a little discription about what I'm doing.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Cleaning of  \"latitude\" and \"longitude\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def size_mb(x):\n",
    "    \"\"\"return the size in megabytes of one obeject\"\"\"\n",
    "    \n",
    "    bytes_size = sys.getsizeof(x)\n",
    "    \n",
    "    return (bytes_size /(1024*1024))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of checkins raw_dataset: 669.74 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of checkins raw_dataset: %.2f MB\" %  size_mb(data_checkins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Friendship network raw_dataset: 29.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of Friendship network raw_dataset: %.2f MB\" %  size_mb(data_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimination of latitude and longitude columns\n",
    "data_checkins.drop(['latitude', 'longitude'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of checkins without latitude and longitude: 571.43 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of checkins without latitude and longitude: %.2f MB\" %  size_mb(data_checkins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Pre-processing check-in time\n",
    "Now the date is type string, let's change it to python date type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_checkins['check-in time'] = pd.to_datetime(data_checkins['check-in time'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>check-in time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>343</td>\n",
       "      <td>2009-08-21 03:01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>576</td>\n",
       "      <td>2009-10-05 20:19:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>24</td>\n",
       "      <td>2009-02-05 06:27:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>310</td>\n",
       "      <td>2009-12-06 22:51:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>5164</td>\n",
       "      <td>2010-01-25 01:29:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user       check-in time\n",
       "location id                          \n",
       "8904          343 2009-08-21 03:01:19\n",
       "8904          576 2009-10-05 20:19:24\n",
       "8904           24 2009-02-05 06:27:43\n",
       "8904          310 2009-12-06 22:51:49\n",
       "8904         5164 2010-01-25 01:29:46"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_checkins.sort_values(by=['location id'], inplace = True)\n",
    "data_checkins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of checkins with date pre-processed: 147.47 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of checkins with date pre-processed: %.2f MB\" %  size_mb(data_checkins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify\"> We could see how just adjusting the datatype of the <b><em>\"check-in time\"</em></b> we achieve a huge reduction of the size of our principal dataset.\n",
    "\n",
    "Let's check if there is some missing value\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Checking missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user             0\n",
       "check-in time    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_checkins.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_edges.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> There is not missing values in both datasets, so we can continue.\n",
    "\n",
    "I think we can reduce even more the datasets size.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 sparse matrix\n",
    "\n",
    "<p style=\"text-align:justify\"> To solve our challenge we can implemnt sparce matrices, with help of dicts.</p> \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparceMatrix:\n",
    "    \"\"\" \n",
    "    \n",
    "    Object for manage big matrices with a \n",
    "    hugue amount of NaN or repteaded values.\n",
    "    \n",
    "    based in python dicts\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__matrix = {} #private attribute\n",
    "        \n",
    "    def row_exist(self, row_id):\n",
    "        if not row_id in self.__matrix:\n",
    "            return False\n",
    "    \n",
    "    def get_row(self,row_id):\n",
    "        if row_exist(self, row_id):\n",
    "            return self.__matrix[row_id]\n",
    "        return False;\n",
    "    \n",
    "    def element_exist(self, row_id, col_id):\n",
    "        try:\n",
    "            if not row_id in self.__matrix:\n",
    "                return False\n",
    "\n",
    "            if col_id in self.get_row(row_id):\n",
    "                return True\n",
    "            return False\n",
    "        except ValueError:\n",
    "            print(\"you are using a unidimesional version, this version not has col_id\") \n",
    "    \n",
    "    def get_val(self, row_id, col_id):\n",
    "        try:\n",
    "            return self.__matrix[row_id][col_id]\n",
    "        except ValueError:\n",
    "            print(\"you are using a unidimesional version, this version not has col_id\") \n",
    "        #return self.__matrix[row_id][col_id]\n",
    "    \n",
    "    def get_index(self):\n",
    "        return self.__matrix.keys()\n",
    "    \n",
    "    def get_matrix(self):\n",
    "        return self.__matrix\n",
    "    \n",
    "    def append(self, row_id, k, col_id = None):\n",
    "        \"\"\"\n",
    "        add a new item.\n",
    "        \n",
    "        k could be any type of data.\n",
    "        \"\"\"\n",
    "        if col_id is None:\n",
    "            if  row_id in self.__matrix:\n",
    "                self.__matrix[row_id].update(k)\n",
    "            else:\n",
    "                self.__matrix[row_id] = k\n",
    "        else:\n",
    "            if  row_id in self.__matrix:\n",
    "                self.__matrix[row_id].update({col_id: k})\n",
    "            else:\n",
    "                self.__matrix[row_id] = {col_id: k}\n",
    "       \n",
    "    \n",
    "    def update(self, row_id, k, col_id = None):\n",
    "        \"\"\"\n",
    "        update item in the position [row_id, col_id].\n",
    "        \n",
    "        k could be any type of data.\n",
    "        \"\"\"\n",
    "        \n",
    "        if col_id is None:\n",
    "            self.__matrix[row_id] = k\n",
    "        else:\n",
    "            self.__matrix[row_id][col_id] = k \n",
    "        \n",
    "        \n",
    "    def concat(self, Matrix):\n",
    "        self.__matrix.update(Matrix.get_matrix())\n",
    "    \n",
    "    def pprint(self, k = 4):\n",
    "        \"\"\" \n",
    "        print the rows of the matrix\n",
    "        \n",
    "        by defect print the first 5 \n",
    "        \"\"\"\n",
    "        \n",
    "        counter = 0\n",
    "        for x, y in self.__matrix.items():\n",
    "            print(f'{x} -> {y}')\n",
    "            counter += 1\n",
    "            if counter == k :\n",
    "                break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 transforming representation of data\n",
    "\n",
    "<p style=\"text-align:justify\"> Now, that we have our class SparceMatrix we can represent our datasets: Checkins and friendship network, and our result set: stalker_classification, in this data structure. It definetly will reduce the size in RAM of our datasets and it will provide more performance in our <b><em>step 3. Processing.</em></b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Transformation of data_checkins\n",
    "\n",
    "<p> For this transformation let's make some asumptions:\n",
    "    <ul>\n",
    "        <li>based on the definition of the challenger: <em>\"stalker is someone who, in this dataset, visits some of the same locations as another person, after the other person goes to that location.\"</em>  we could say that there is not timestap defined, in this way we could say that if the person <em>A</em> went to the place <em>X</em> the 01/01/2020 and the person <em>B</em> went to the same place the 05/01/2020 B will be considered has staleker of <em>A</em>. It means that while: $$A_{date}(X) < B_{date}(X) \\implies (A,B) = 1 $$\n",
    "this is valid for each place</li>\n",
    "        <li>\n",
    "            Using the previous assumption we could say that for our analysis we only need at most two dates for each user over one place: the first date that the user has visted the place and the last date, obviously there are users that has visited a certain place just one time, in this case we will use just one date. It will reduce the size of our dataset, because there are user that are made chekin more than two times in the same place, for example in their jobs. \n",
    "        </li>\n",
    "        <br>\n",
    "        <li>\n",
    "            if A place x just has been visited by one user, for our challenge is useless, so let delete this places, it will reduce more the size of our pre-procesed dataset\n",
    "        </li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use this to measure the time that takes execute a function\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first create our sparse matrix \n",
    "locations_chekins = SparceMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280969\n"
     ]
    }
   ],
   "source": [
    "#lets extract the unique ids of the places\n",
    "location_ids = data_checkins.index.unique()\n",
    "print(len(location_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the time that have taked pre process the data_checkins\n",
      "2685.626620054245\n"
     ]
    }
   ],
   "source": [
    "#lets calc the time:\n",
    "# Start the stopwatch / counter \n",
    "start = time.time()\n",
    "for location_id in location_ids:\n",
    "    #select the users and dates\n",
    "    location_checkins = data_checkins.loc[location_id]\n",
    "    #ommiting the places with just one visitor\n",
    "    if location_checkins.size > 2:\n",
    "        #lets change the index for the users id\n",
    "        location_checkins.reset_index(inplace = True)\n",
    "        location_checkins.set_index(\"user\", inplace = True)\n",
    "        #lets extract the unique ids of the users that visited the place\n",
    "        user_ids = location_checkins.index.unique()\n",
    "        #ommit locations with just one visitor\n",
    "        if len(user_ids) > 1:\n",
    "            #lets extract the dates in wich each user has visited the place\n",
    "            for user_id in user_ids:\n",
    "                user_dates = location_checkins.loc[user_id]\n",
    "                #more than one visit?\n",
    "                # two because a df with just one register has a dimensionality of 2 \n",
    "                if user_dates.size > 2:\n",
    "                    #extract the first and last date\n",
    "                    first_date = user_dates[\"check-in time\"].min()\n",
    "                    last_date = user_dates[\"check-in time\"].max()\n",
    "                    #lets add this register to our SparceMatrix\n",
    "                    locations_chekins.append(location_id, user_id, [first_date,last_date])\n",
    "                else:\n",
    "                    date = user_dates[\"check-in time\"]\n",
    "                    #lets add this register to our SparceMatrix\n",
    "                    locations_chekins.append(location_id, user_id, date)\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "            \n",
    "#cleaning vars\n",
    "del location_id, location_checkins, user_ids, user_id, user_dates, first_date, last_date, date\n",
    "\n",
    "# Stop the stopwatch / counter \n",
    "stop = time.time() \n",
    "print(\"This is the time that have taked pre process the data_checkins\")\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load / save the pre-processed files\n",
    "def load_obj(path):\n",
    "    pickle_in = open(path,\"rb\")\n",
    "    obj = pickle.load(pickle_in)\n",
    "    return obj\n",
    "\n",
    "def save_obj(obj, path):\n",
    "    #save the preprocessed data\n",
    "    pickle_out = open( path + \".pickle\",\"wb\")\n",
    "    pickle.dump(obj, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_obj(locations_chekins, \"locations_chekins\")\n",
    "locations_chekins = load_obj(\"locations_chekins.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lets see the size of our dataset after the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the size of our dataset already pre-processed: \n",
      "40.00010681152344\n"
     ]
    }
   ],
   "source": [
    "print(\"this is the size of our dataset already pre-processed: \")\n",
    "print(size_mb(locations_chekins.get_matrix()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> we could see that from our initial size of 700 MB we have reduce it until 40 MB it is a reduction of 94.29%. For other hand the pre process has take arround 43 minutes, let see if we could implement concurrency to reduce this time and get the same result</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1.1 applying concurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use this  function for the concurrency\n",
    "def split_list(array, n_splits = 4):\n",
    "    \"\"\" this function split a lsit in almost equal parts\"\"\"\n",
    "    \n",
    "    splits = []\n",
    "    delta = math.floor((len(array)/n_splits))\n",
    "    for i in range(n_splits):\n",
    "        if i == n_splits - 1 :\n",
    "            a = array[(i*delta): ]\n",
    "            splits.append(a)\n",
    "        else:\n",
    "            a = array[(i*delta) : ((i+1)*delta)]\n",
    "            splits.append(a)\n",
    "            \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_preprocessing(loc_ids, data_checkins):\n",
    "    \"\"\" \n",
    "    this function will be executed for the threads\n",
    "    \n",
    "    this function will extract our useful data \n",
    "    of a user that has visted a place \n",
    "    \"\"\"\n",
    "    \n",
    "    temp = SparceMatrix()\n",
    "    \n",
    "    for location_id in loc_ids:\n",
    "        #select the users and dates\n",
    "        location_checkins = data_checkins.loc[location_id]\n",
    "        #ommiting the places with just one visit\n",
    "        if location_checkins.size > 2:\n",
    "            #lets change the index for the users id\n",
    "            location_checkins.reset_index(inplace = True)\n",
    "            location_checkins.set_index(\"user\", inplace = True)\n",
    "            #lets extract the unique ids of the users that visited the place\n",
    "            user_ids = location_checkins.index.unique()\n",
    "            #ommit locations with just one visitor\n",
    "            if len(user_ids) > 1:\n",
    "                #lets extract the dates in wich each user has visited the place\n",
    "                for user_id in user_ids:\n",
    "                    user_dates = location_checkins.loc[user_id]\n",
    "                    #more than one visit?\n",
    "                    # two because a df with just one register has a dimensionality of 2 \n",
    "                    if user_dates.size > 2:\n",
    "                        #extract the first and last date\n",
    "                        first_date = user_dates[\"check-in time\"].min()\n",
    "                        last_date = user_dates[\"check-in time\"].max()\n",
    "                        #lets add this register to our SparceMatrix\n",
    "                        temp.append(location_id, user_id, [first_date,last_date])\n",
    "                    else:\n",
    "                        date = user_dates[\"check-in time\"]\n",
    "                        #lets add this register to our SparceMatrix\n",
    "                        temp.append(location_id, user_id, date)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    #cleaning vars\n",
    "    del location_id, location_checkins, user_ids, user_id, user_dates, first_date, last_date, date\n",
    "    return temp\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create te sparce matrix for concurrency\n",
    "concurrency_locations_chekins = SparceMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the time that have taked pre process concurrently the data_checkins\n",
      "1407.0616173744202\n"
     ]
    }
   ],
   "source": [
    "# Start the stopwatch / counter \n",
    "start = time.time()\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    split_loc_ids = split_list(location_ids, 6)\n",
    "    results = [executor.submit(location_preprocessing, split, data_checkins) for split in split_loc_ids]\n",
    "    \n",
    "    for f in concurrent.futures.as_completed(results):\n",
    "        concurrency_locations_chekins.concat(f.result())\n",
    "        \n",
    "# Stop the stopwatch / counter \n",
    "stop = time.time() \n",
    "print(\"This is the time that have taked pre process concurrently the data_checkins\")\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_obj(concurrency_locations_chekins, \"output/concurrency_locations_chekins\")\n",
    "concurrency_locations_chekins = load_obj(\"output/concurrency_locations_chekins.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the size of our dataset already pre-processed: \n",
      "20.000099182128906\n"
     ]
    }
   ],
   "source": [
    "print(\"this is the size of our dataset already pre-processed: \")\n",
    "print(size_mb(concurrency_locations_chekins.get_matrix()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that we could have the same result in almost te middle of the time, i think that whit a graphic card it could be even faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 transforming  data_edges\n",
    "<p> Like the data_checkins this information will be stored in a sparse matrix. We could say that, for be a non directed graph,  if $u_0$ is friend of $u_1$ so $u_1$ is friend of $u_0$. $$ if (u_0,u_1) \\implies (u_1,u_0)$$ In this way and for use less space and perform the search fastly we could sort ascendig the user_id, and store the friendship relation  between ($u_0$, $u_1$) in the user list that has the smallest id</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1\n",
       "0   \n",
       "0  1\n",
       "0  2\n",
       "0  3\n",
       "0  4\n",
       "0  5"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_edges.set_index(0, inplace=True)\n",
    "data_edges.sort_index(inplace=True)\n",
    "data_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of raw data_edges: 29.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of raw data_edges: %.2f MB\" %  size_mb(data_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let see the numebr of unique users\n",
    "users = data_edges.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196591\n"
     ]
    }
   ],
   "source": [
    "print(len(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_preprocessing(user_ids, data_edges):\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1\n",
       "0        \n",
       "0       1\n",
       "0       2\n",
       "0       3\n",
       "0       4\n",
       "0       5\n",
       "0       6\n",
       "0       7\n",
       "0       8\n",
       "0       9\n",
       "0      10\n",
       "0      11\n",
       "0      12\n",
       "0      13\n",
       "0      14\n",
       "0      15\n",
       "0      16\n",
       "0      17\n",
       "0      18\n",
       "0      19\n",
       "0      20\n",
       "0      21\n",
       "0      22\n",
       "0      23\n",
       "0      24\n",
       "0      25\n",
       "0      26\n",
       "0      27\n",
       "0      28\n",
       "0      29\n",
       "0      30\n",
       "..    ...\n",
       "0     586\n",
       "0     587\n",
       "0     588\n",
       "0     589\n",
       "0     590\n",
       "0     591\n",
       "0     592\n",
       "0     593\n",
       "0     594\n",
       "0     595\n",
       "0     596\n",
       "0     597\n",
       "0     598\n",
       "0     599\n",
       "0     600\n",
       "0     601\n",
       "0     602\n",
       "0     603\n",
       "0     604\n",
       "0     605\n",
       "0     606\n",
       "0     607\n",
       "0     608\n",
       "0     609\n",
       "0     610\n",
       "0     611\n",
       "0     612\n",
       "0     613\n",
       "0     614\n",
       "0   69828\n",
       "\n",
       "[615 rows x 1 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_edges.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "aleatorios = [random.randint(0,1000) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_checkins.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = data_checkins.loc[8904]\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location id</th>\n",
       "      <th>user</th>\n",
       "      <th>check-in time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8904</td>\n",
       "      <td>343</td>\n",
       "      <td>2009-08-21 03:01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8904</td>\n",
       "      <td>576</td>\n",
       "      <td>2009-10-05 20:19:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8904</td>\n",
       "      <td>24</td>\n",
       "      <td>2009-02-05 06:27:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8904</td>\n",
       "      <td>310</td>\n",
       "      <td>2009-12-06 22:51:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8904</td>\n",
       "      <td>5164</td>\n",
       "      <td>2010-01-25 01:29:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8904</td>\n",
       "      <td>256</td>\n",
       "      <td>2010-09-19 01:47:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8904</td>\n",
       "      <td>343</td>\n",
       "      <td>2009-05-28 23:40:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8904</td>\n",
       "      <td>392</td>\n",
       "      <td>2009-12-17 23:02:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8904</td>\n",
       "      <td>256</td>\n",
       "      <td>2010-04-24 23:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8904</td>\n",
       "      <td>343</td>\n",
       "      <td>2009-06-20 01:40:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8904</td>\n",
       "      <td>343</td>\n",
       "      <td>2009-03-08 02:09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8904</td>\n",
       "      <td>256</td>\n",
       "      <td>2009-05-30 03:33:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    location id  user       check-in time\n",
       "0          8904   343 2009-08-21 03:01:19\n",
       "1          8904   576 2009-10-05 20:19:24\n",
       "2          8904    24 2009-02-05 06:27:43\n",
       "3          8904   310 2009-12-06 22:51:49\n",
       "4          8904  5164 2010-01-25 01:29:46\n",
       "5          8904   256 2010-09-19 01:47:05\n",
       "6          8904   343 2009-05-28 23:40:31\n",
       "7          8904   392 2009-12-17 23:02:42\n",
       "8          8904   256 2010-04-24 23:57:00\n",
       "9          8904   343 2009-06-20 01:40:01\n",
       "10         8904   343 2009-03-08 02:09:11\n",
       "11         8904   256 2009-05-30 03:33:23"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.reset_index(inplace=True)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.set_index(\"user\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "44458   2010-07-25 18:13:48\n",
      "44458   2010-04-20 17:56:37\n",
      "Name: check-in time, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "h = k.loc[44458]\n",
    "print(h[\"check-in time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(h.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-04-20 17:56:37\n",
      "2010-07-25 18:13:48\n"
     ]
    }
   ],
   "source": [
    "h = k.loc[44458]\n",
    "print(h[\"check-in time\"].min())\n",
    "print(h[\"check-in time\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-dd7ad1aced8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eureka\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "if not hsize:\n",
    "    print(\"eureka\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = data_checkins.iloc[0]\n",
    "for i in k:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's transform our dataset\n",
    "x = 4\n",
    "k = data_checkins.iloc[:x]\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SparceMatrix()\n",
    "m.append(1, 1, [1,10])\n",
    "m.append(1, 2, [3,10])\n",
    "m.append(1, 3, [11,19])\n",
    "m.append(1, 4, [20,23])\n",
    "\n",
    "m.append(2, 1, [4,15])\n",
    "m.append(2, 2, [6,20])\n",
    "m.append(2, 3, [25,26])\n",
    "m.append(2, 4, [27,28])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = m.get_row(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.exist(123, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = SparceMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user, dates in k.items():\n",
    "    current_first = dates[0]\n",
    "    current_last = dates[1]\n",
    "    for next_user, next_dates in k.items():\n",
    "        if user != next_user:\n",
    "            next_first = next_dates[0]\n",
    "            next_last = next_dates[1]\n",
    "            \n",
    "            # comparacion de doble via\n",
    "            \n",
    "            # si la primera date del current es menor a la ultima date de check-in del next\n",
    "            # next es saltalker de  current\n",
    "            # estrictamente menor porque  el reto dice explicitamente en el futuro.\n",
    "            if current_first < next_last:\n",
    "                if m2.exist(user, next_user):\n",
    "                    score = m2.get_val(user, next_user) \n",
    "                    m2.update(user, next_user, score + 1)\n",
    "                else:\n",
    "                    m2.append(user, next_user, 1)\n",
    "            # si la primera data the next user es menor a la ultima data de current user\n",
    "            #current user es stalker the next\n",
    "            if next_first < current_last:\n",
    "                if m2.exist(next_user, user):\n",
    "                    score = m2.get_val(next_user, user) \n",
    "                    m2.update(next_user, user, score + 1)\n",
    "                else:\n",
    "                    m2.append(next_user, user, 1)\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> After create our class SparseMatrix we will start to transform our datasets in \n",
    "     The matrixes that we'll implement are shown in the next images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = { \n",
    "    1:[1212, 1414],\n",
    "    2:[1313, 1515]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\n",
    "    123 : { \n",
    "        1:[1212, 1414],\n",
    "        2:[1313, 1515]\n",
    "    },\n",
    "    234 : [{1:[1212, 1414]}, {2:[1313, 1515]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[123][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate as tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkins = (tc.SFrame.read_csv(\n",
    "    path_checkins, delimiter='\\t', header=False).rename({'X1': 'user_id',\n",
    "                                                          'X2' : 'checkin_ts',\n",
    "                                                          'X3': 'lat', \n",
    "                                                          'X4' : 'lon',\n",
    "                                                          'X5': 'location_id'})\n",
    "            [[\"user_id\", \"location_id\", \"checkin_ts\"]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chin_ps = ( checkins.join( checkins, on = 'location_id' )\n",
    "                    .rename( {'checkin_ts'   : 'checkin_ts_ee',\n",
    "                              'checkin_ts.1' : 'checkin_ts_er',\n",
    "                              'user_id'      : 'stalkee' ,\n",
    "                              'user_id.1'    : 'stalker' } ) )\n",
    "\n",
    "pairs_filtered = chin_ps[ (chin_ps['checkin_ts_ee'] < chin_ps['checkin_ts_er']) &\n",
    "                          (chin_ps['stalkee'] != chin_ps['stalker']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = ( pairs_filtered[['stalkee', 'stalker', 'location_id']]\n",
    "                    .unique()\n",
    "                    .groupby( ['stalkee','stalker'] ,\n",
    "                               {\"location_count\" : agg.COUNT })\n",
    "                    .topk( 'location_count', k=5 )\n",
    "                    .materialize() )\n",
    "\n",
    "print( final_result ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
